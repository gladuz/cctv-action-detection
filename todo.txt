1. note that we can't use "pytorchvideo" because it needs python 3.7, 3.8.
we have to use python 3.6.9 due to the compatibility with tensorRT.

so i wrote a code for no-pytorchvideo version for rgb extraction but somehow
it doesn't work with my computer.

so i decided to use pytorchvideo version to extract rgb frames for training now,
and i will try to find a way to fix the problem later.

2. now i'm running extraction-rgb.py with pytorchvideo version on my
local computer. (ETA is around 15 hours. p.s. now it's Oct 8th 00:00 am)

3. can you code for extraction-flow.py? to extract flow frames from resized videos and
"SAVE" them in the processed_data folder?

later (ASAP), we can connect those two codes to make a single code for rgb and flow extraction.

and then, we can train the model with rgb and flow features (vector)

[1002]
1. have to fix an below error in "extraction-flow.py" code.

Currently processing: G:\내 드라이브\Project\RGBLab\ABB\Data\01.폭행(assult)\inside_croki_02\24-5\24-5_cam01_assault01_place09_night_winter.mp4       
Extracting features:   0%|                                                   | 0/42 [00:48<?, ?it/s]                         | 0/1923 [00:00<?, ?it/s]
Error occured while processing: G:\내 드라이브\Project\RGBLab\ABB\Data\01.폭행(assult)\inside_croki_02\24-5\24-5_cam01_assault01_place09_night_winter.mp4
Error message: The size of tensor a (57) must match the size of tensor b (56) at non-singleton dimension 3

[1014]
1. Currently LSTR/train.py seems to work. but we have to re-extract the features as you know,
it is just a test code (baseline) for now.

2. i also coded some naive custom_data_loader in LSTR/custom_data_loader.py.
    - We might need to use LSTR codebase for this. Because we might need random sampling of clips, multilabel support etc..

3. let me know when your extraction for image and features are done.
    - Image extraction is running now (11pm) ETA is ~8 hours. Will be around 100GB.
    - I will run feature extraction after that
    - I will also change the labels to the big 3 (assault and stuff)
        - We might need to discuss this. Because each video has only small part of the video 
            with continuous action. Model might not generalize well for unseen videos.
4. have to add evaluation code to LSTR/train.py but it will not be hard.