{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique action names: {'piercing', 'stop and go', 'punching', 'threaten', 'kicking', 'running', 'pulling', 'around', 'climbwall', 'pushing', 'throwing', 'walking', 'falldown'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"G:\\내 드라이브\\Project\\RGBLab\\ABB\\Data\"\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_xml_for_actionname(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    action_names = []\n",
    "\n",
    "    for action in root.findall(\".//action\"):\n",
    "        action_name_element = action.find(\"actionname\")\n",
    "        if action_name_element is not None:\n",
    "            action_names.append(action_name_element.text)\n",
    "\n",
    "    return action_names\n",
    "\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"./processed_data\", 'data_files.csv'))\n",
    "actions = set()\n",
    "for index, row in df.iterrows():\n",
    "    xml_file = os.path.join(DATA_PATH, row['path'], row['filename']+'.xml')\n",
    "    try:\n",
    "        action_names = parse_xml_for_actionname(xml_file)\n",
    "        actions.update(action_names)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {xml_file} not found.\")\n",
    "    except ET.ParseError:\n",
    "        print(f\"Error parsing {xml_file}\")\n",
    "\n",
    "print(\"Unique action names:\", actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/ict06/.conda/envs/torch21/lib/python3.8/site-packages/spatial_correlation_sampler_backend.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/ict06/dev/abb_project/for_test/util2.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B155.230.134.107/home/ict06/dev/abb_project/for_test/util2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcombined_flow_extractor\u001b[39;00m \u001b[39mimport\u001b[39;00m CombinedFlowModel\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B155.230.134.107/home/ict06/dev/abb_project/for_test/util2.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m CombinedFlowModel()\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:3\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/abb_project/combined_flow_extractor.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbn_inception\u001b[39;00m \u001b[39mimport\u001b[39;00m BNInception, get_bninception\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflownet\u001b[39;00m \u001b[39mimport\u001b[39;00m FastFlowNet, get_flownet\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m trange\n",
      "File \u001b[0;32m~/dev/abb_project/flownet.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspatial_correlation_sampler\u001b[39;00m \u001b[39mimport\u001b[39;00m SpatialCorrelationSampler\n\u001b[1;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCorrelation\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m     10\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, max_displacement):\n",
      "File \u001b[0;32m~/.conda/envs/torch21/lib/python3.8/site-packages/spatial_correlation_sampler/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mspatial_correlation_sampler\u001b[39;00m \u001b[39mimport\u001b[39;00m SpatialCorrelationSampler, spatial_correlation_sample\n",
      "File \u001b[0;32m~/.conda/envs/torch21/lib/python3.8/site-packages/spatial_correlation_sampler/spatial_correlation_sampler.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunction\u001b[39;00m \u001b[39mimport\u001b[39;00m once_differentiable\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _pair\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspatial_correlation_sampler_backend\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcorrelation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspatial_correlation_sample\u001b[39m(input1,\n\u001b[1;32m     10\u001b[0m                                input2,\n\u001b[1;32m     11\u001b[0m                                kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                dilation\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     16\u001b[0m                                dilation_patch\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     17\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply spatial correlation sampling on from input1 to input2,\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[39m    Every parameter except input1 and input2 can be either single int\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/ict06/.conda/envs/torch21/lib/python3.8/site-packages/spatial_correlation_sampler_backend.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK2at6Tensor6deviceEv"
     ]
    }
   ],
   "source": [
    "from combined_flow_extractor import CombinedFlowModel\n",
    "model = CombinedFlowModel().to(device='cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ict06/dev/abb_project\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bn_inception import get_bninception\n",
    "from combined_flow_extractor import CombinedFlowModel\n",
    "from resnet import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet50()\n",
    "        self.flow = CombinedFlowModel()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out_f = self.flow(x[:, :, : , :])\n",
    "        out_r = self.resnet(x[:, :3, :, :])\n",
    "        return torch.cat((out_f.squeeze(2,3), out_r), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.09044694900513\n"
     ]
    }
   ],
   "source": [
    "model = Extractor()\n",
    "model.to('cuda:3')\n",
    "model.eval()\n",
    "import time\n",
    "a = torch.randn(5, 6, 512, 512).to('cuda:3')\n",
    "with torch.no_grad():\n",
    "    st = time.time()\n",
    "    for i in range(100):\n",
    "        model(a)\n",
    "    print((time.time()-st) * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.20076584815979\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704.0556640625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated('cuda:3') / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-10-28 01:07:01 3609271:3609271 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-10-28 01:07:01 3609271:3609271 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-10-28 01:07:01 3609271:3609271 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n",
      "[W collection.cpp:700] Warning: Failed to recover relationship between all profiler and kineto events: 1360 vs. 0  reassociated. (function reassociate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b          1360  \n",
      "                                  cudaStreamIsCapturing         0.15%      41.000us         0.15%      41.000us       0.133us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           308  \n",
      "                                  cudaStreamGetPriority         0.14%      37.000us         0.14%      37.000us       0.120us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           308  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.15%      39.000us         0.15%      39.000us       0.127us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           308  \n",
      "                                       cudaLaunchKernel        92.55%      24.628ms        92.55%      24.628ms      23.103us       0.000us         0.00%       0.000us       0.000us           0 b           0 b          1066  \n",
      "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us      21.000us         0.21%      21.000us       2.333us           0 b           0 b             9  \n",
      "                                        cudaMemsetAsync         1.10%     294.000us         1.10%     294.000us       6.255us       0.000us         0.00%       0.000us       0.000us           0 b           0 b            47  \n",
      "            cudnn_ampere_scudnn_128x32_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     101.000us         1.01%     101.000us      25.250us           0 b           0 b             4  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     494.000us         4.93%     494.000us       3.829us           0 b           0 b           129  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     177.000us         1.76%     177.000us       3.471us           0 b           0 b            51  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 26.611ms\n",
      "Self CUDA time total: 10.029ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CUDA],\n",
    "        profile_memory=True, record_shapes=True) as prof:\n",
    "    model(a)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b          1360  \n",
      "                                  cudaStreamIsCapturing         0.15%      41.000us         0.15%      41.000us       0.133us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           308  \n",
      "                                  cudaStreamGetPriority         0.14%      37.000us         0.14%      37.000us       0.120us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           308  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.15%      39.000us         0.15%      39.000us       0.127us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           308  \n",
      "                                       cudaLaunchKernel        92.55%      24.628ms        92.55%      24.628ms      23.103us       0.000us         0.00%       0.000us       0.000us           0 b           0 b          1066  \n",
      "void cask_cudnn::computeOffsetsKernel<false, false>(...         0.00%       0.000us         0.00%       0.000us       0.000us      21.000us         0.21%      21.000us       2.333us           0 b           0 b             9  \n",
      "                                        cudaMemsetAsync         1.10%     294.000us         1.10%     294.000us       6.255us       0.000us         0.00%       0.000us       0.000us           0 b           0 b            47  \n",
      "            cudnn_ampere_scudnn_128x32_relu_small_nn_v1         0.00%       0.000us         0.00%       0.000us       0.000us     101.000us         1.01%     101.000us      25.250us           0 b           0 b             4  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     494.000us         4.93%     494.000us       3.829us           0 b           0 b           129  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     177.000us         1.76%     177.000us       3.471us           0 b           0 b            51  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 26.611ms\n",
      "Self CUDA time total: 10.029ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_memory_usage\", row_limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(32, 6, 512, 512).to('cuda:3')\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='with torch.no_grad(): model(a)',\n",
    "    setup='from combined_flow_extractor import CombinedFlowModel; model=CombinedFlowModel();model.to(\"cuda:3\")',\n",
    "    globals={'a': a})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f3ec240a070>\n",
      "with torch.no_grad(): model(a)\n",
      "setup: from combined_flow_extractor import CombinedFlowModel; model=CombinedFlowModel();model.to(\"cuda:3\")\n",
      "  238.76 ms\n",
      "  1 measurement, 100 runs , 1 thread\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abb_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
